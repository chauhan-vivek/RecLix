{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from rake_nltk import Rake\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_13236\\1943832321.py:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = pd.DataFrame().append([df1,df2,df3, df4])\n"
     ]
    }
   ],
   "source": [
    "path = 'C:/Users/hp/Desktop/rec-flix/data/raw/'\n",
    "file1 = 'netflix_titles.csv'\n",
    "file2 = 'amazon_prime_titles.csv'\n",
    "file3 = 'disney_plus_titles.csv'\n",
    "file4 = 'hulu_titles.csv'\n",
    "df1 = pd.read_csv(os.path.join(path, file1))\n",
    "df2 = pd.read_csv(os.path.join(path, file2))\n",
    "df3 = pd.read_csv(os.path.join(path, file3))\n",
    "df4 = pd.read_csv(os.path.join(path, file4))\n",
    "df = pd.DataFrame().append([df1,df2,df3, df4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of columns with Null values: 3\n",
      "Now, are there Na values: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_13236\\3256741079.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_bow.dropna(inplace=True)\n"
     ]
    }
   ],
   "source": [
    "df_bow=df[['title','director','cast','listed_in','description']]\n",
    "print(f'Number of columns with Null values: {df_bow.isna().any().sum()}')\n",
    "#drop na values\n",
    "df_bow.dropna(inplace=True)\n",
    "print(f'Now, are there Na values: {True if df_bow.isna().any().sum() else False}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_13236\\590408319.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_bow.drop(columns=['description'],inplace=True)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_13236\\590408319.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_bow['cast'] = df_bow['cast'].map(lambda x : x.split(',')[:3])\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_13236\\590408319.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_bow['listed_in'] = df_bow['listed_in'].map(lambda x: x.lower().split(','))\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_13236\\590408319.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_bow['director'] = df_bow['director'].map(lambda x: x.split(' '))\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_13236\\590408319.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_bow['bag_of_words']=\"\"\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_13236\\590408319.py:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_bow.drop(columns=[col for col in df_bow.columns if col!='bag_of_words'],inplace=True)\n"
     ]
    }
   ],
   "source": [
    "for index,row in df_bow.iterrows():\n",
    "    description=row['description']\n",
    "    r=Rake()\n",
    "    r.extract_keywords_from_text(description)\n",
    "    key_words_dict_scores=r.get_word_degrees()\n",
    "    row['Key_words']=list(key_words_dict_scores.keys())\n",
    "\n",
    "df_bow.drop(columns=['description'],inplace=True)\n",
    "\n",
    "df_bow['cast'] = df_bow['cast'].map(lambda x : x.split(',')[:3])\n",
    "df_bow['listed_in'] = df_bow['listed_in'].map(lambda x: x.lower().split(','))\n",
    "df_bow['director'] = df_bow['director'].map(lambda x: x.split(' '))\n",
    "\n",
    "for index,row in df_bow.iterrows():\n",
    "    row['cast']= [x.lower().replace(',',' ') for x in row['cast']]\n",
    "    row['director']=''.join(row['director']).lower()\n",
    "\n",
    "df_bow.set_index('title',inplace=True)\n",
    "\n",
    "df_bow['bag_of_words']=\"\"\n",
    "columns=df_bow.columns\n",
    "for index,row in df_bow.iterrows():\n",
    "    words= \"\"\n",
    "    for col in columns:\n",
    "        if col != 'director':\n",
    "            words= words + ' '.join(row[col])+ ' '\n",
    "        else:\n",
    "            words= words + row[col] + ' '\n",
    "    row['bag_of_words']=words\n",
    "\n",
    "df_bow.drop(columns=[col for col in df_bow.columns if col!='bag_of_words'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "count=CountVectorizer()\n",
    "count_matrix=count.fit_transform(df_bow['bag_of_words'])\n",
    "indices=pd.Series(df_bow.index)\n",
    "cosine_sim=cosine_similarity(count_matrix,count_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommendations(Title,cosine_sim=cosine_sim):\n",
    "    recommended_movies=[]\n",
    "    idx=indices[indices==Title].index[0]\n",
    "    score_series=pd.Series(cosine_sim[idx]).sort_values(ascending=False)\n",
    "    top_10_indexes=list(score_series.iloc[1:11].index)\n",
    "    \n",
    "    for i in top_10_indexes:\n",
    "        recommended_movies.append(list(df_bow.index)[i])\n",
    "    return recommended_movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movies recommended based on your input are :\n",
      " ['PK', 'Gori Tere Pyaar Mein', 'Talaash', 'Ek Main Aur Ekk Tu', 'Raja Hindustani', 'Dil Chahta Hai', 'Kapoor & Sons', 'Dil', 'Chup Chup Ke', 'Fida']\n"
     ]
    }
   ],
   "source": [
    "recommended_movies = recommendations('3 Idiots')\n",
    "print(f\"Movies recommended based on your input are :\\n {recommended_movies}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movies recommended based on your input are :\n",
      " ['Bad Boys II', 'Blue Streak', 'Wild Wild West', 'Men in Black', 'Men in Black II', 'The Other Guys', 'Aladdin (2019)', \"King's Ransom\", 'Jumping Ship', 'Bright']\n"
     ]
    }
   ],
   "source": [
    "recommended_movies = recommendations('Bad Boys')\n",
    "print(f\"Movies recommended based on your input are :\\n {recommended_movies}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bow.reset_index(inplace=True)\n",
    "pickle.dump(df_bow.to_dict(), open(r'C:\\Users\\hp\\Desktop\\rec-flix\\models\\all_movies.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           title                                       bag_of_words\n",
      "0      Ganglands  julienleclercq sami bouajila  tracy gotoas  sa...\n",
      "1  Midnight Mass  mikeflanagan kate siegel  zach gilford  hamish...\n"
     ]
    }
   ],
   "source": [
    "all_movies = pickle.load(open(r'C:\\Users\\hp\\Desktop\\rec-flix\\models\\all_movies.pkl','rb'))\n",
    "df_all = pd.DataFrame(all_movies)\n",
    "print(df_all.head(2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(cosine_sim, open(r'C:\\Users\\hp\\Desktop\\rec-flix\\models\\cosine_sim_all.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                             Ganglands\n",
       "1                                         Midnight Mass\n",
       "2                      My Little Pony: A New Generation\n",
       "3                                               Sankofa\n",
       "4                         The Great British Baking Show\n",
       "                              ...                      \n",
       "13527                          X-Men Origins: Wolverine\n",
       "13528    Night at the Museum: Battle of the Smithsonian\n",
       "13529                                   Eddie the Eagle\n",
       "13530                              Bend It Like Beckham\n",
       "13531             Captain Sparky vs. The Flying Saucers\n",
       "Name: title, Length: 13532, dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(df_bow.title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('Flix')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e96efbb85d1a4e5e12fec89ed41d6b314653a99c1bcb1f6e2746c89f5861a009"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
